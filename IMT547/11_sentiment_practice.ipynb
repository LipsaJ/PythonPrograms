{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment & Dictionaries\n",
    "\n",
    "We will mostly be using NLTK to conduct sentiment analysis in this lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK Corpus\n",
    "\n",
    "NLTK has several corpora. Some are useful for sentiment analysis.\n",
    "\n",
    "http://www.nltk.org/howto/corpus.html\n",
    "\n",
    "* opinion_lexicon\n",
    "* WordNet\n",
    "* SentiWordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opinion lexicon\n",
    "\n",
    "Opinion Lexicon: A list of English positive and negative opinion words or sentiment words (around 6800 words). This list was compiled over many years starting from in the paper by (Hu and Liu, KDD-2004).\n",
    "\n",
    "You need to first download this nltk opinion_lexicon corpus\n",
    "`nltk.download('opinion_lexicon')`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('opinion_lexicon') #this download needs to happen for the very first time\n",
    "from nltk.corpus import opinion_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a+', 'abound', 'abounds', 'abundance', 'abundant', ...]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinion_lexicon.positive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(opinion_lexicon.positive())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-faced', '2-faces', 'abnormal', 'abolish', ...]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinion_lexicon.negative()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4783"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(opinion_lexicon.negative())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span class=\"mark\">Your turn</span>**: think of three positive and negative sentiment words. See if they are in the lexicons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with your own words\n",
    "my_pos = ['happy','alright','groovy']\n",
    "my_neg = ['psycho','retarded','nasty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD, POS, NEG\n",
      "---------------\n",
      "happy True False\n",
      "alright False False\n",
      "groovy False False\n",
      "psycho False False\n",
      "retarded False True\n",
      "nasty False True\n"
     ]
    }
   ],
   "source": [
    "# run this to see if they are in any of the lexicon\n",
    "print('WORD, POS, NEG\\n---------------')\n",
    "for lex in [my_pos,my_neg]:\n",
    "    for word in lex:\n",
    "        print(word,word in opinion_lexicon.positive(),word in opinion_lexicon.negative())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results tells you that for certain words, opinion_lexicon is not able to assign positive or negative labels. Trying with a non-sentiment word you will see the same result  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment of tweet\n",
    "In the last lab, you all tried tokenizing tweets.\n",
    "\n",
    "**<span class=\"mark\">TODO</span>**: What's the sentiment of a tweet sample? \n",
    "You can try with \"@john lol that was #awesome :)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@', 'john', 'lol', 'that', 'was', '#', 'awesome', ':', ')']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweet = \"@john lol that was #awesome :)\"\n",
    "\n",
    "#your code below\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# tokenize text into words\n",
    "words = word_tokenize(test_tweet)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD, POS, NEG\n",
      "---------------\n",
      "@ False False\n",
      "john False False\n",
      "lol False False\n",
      "that False False\n",
      "was False False\n",
      "# False False\n",
      "awesome True False\n",
      ": False False\n",
      ") False False\n"
     ]
    }
   ],
   "source": [
    "print('WORD, POS, NEG\\n---------------')\n",
    "for lex in [words]:\n",
    "    for word in lex:\n",
    "        print(word,word in opinion_lexicon.positive(),word in opinion_lexicon.negative())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ False False\n",
      "john False False\n",
      "lol False False\n",
      "that False False\n",
      "was False False\n",
      "# False False\n",
      "awesome True False\n",
      ": False False\n",
      ") False False\n"
     ]
    }
   ],
   "source": [
    "# Prof Tanu's Code\n",
    "tweetoken = nltk.word_tokenize(test_tweet)\n",
    "for word in tweetoken:\n",
    "        print(word,word in opinion_lexicon.positive(),word in opinion_lexicon.negative())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentiment analysis with `VADER`\n",
    "https://pypi.org/project/vaderSentiment/\n",
    "\n",
    "VADER Sentiment Analysis. VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer #pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.233, 'pos': 0.767, 'compound': 0.872}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "analyzer.polarity_scores(test_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with another text. News article this time. Recall this text from last lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Netanyahu's visit was cut short by reports late Sunday that a rocket was fired from Gaza into central Israel, wounding at least seven people. Following criticism from political opponents over what they consider the prime minister's unclear stance toward the militant political group, Israel responded with a series of strikes into Gaza against Hamas, which largely governs the contested strip. President Donald Trump tacitly endorsed the strike following his meetings with Netanyahu, calling the Hamas attack \\\"despicable.\\\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.2, 'neu': 0.778, 'pos': 0.023, 'compound': -0.9287}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to interpret the overall score?**\n",
    "\n",
    "The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional measure of sentiment for a given sentence. Calling it a 'normalized, weighted composite score' is accurate.\n",
    "\n",
    "* Positive sentiment: compound score >= 0.05\n",
    "* Neutral sentiment: -0.05 < compound score < 0.05 : \n",
    "* Negative sentiment: compound score <= -0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-dimensional measures of sentiment**\n",
    "\n",
    "The `pos`, `neu`, and `neg` scores are ratios for proportions of text that fall in each category (so these should all add up to be 1... or close to it with float operation). These are the most useful metrics if you want multidimensional measures of sentiment for a given sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span class=\"mark\">TODO</span>**:\n",
    "\n",
    "write function to interpret the overall sentiment of text as positive, negavitve, or neutral based on VADER's analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative sentiment\n"
     ]
    }
   ],
   "source": [
    "# Your code below\n",
    "#implement the logic if else - if compound > - 0.05 then positive\n",
    "\n",
    "# Program checks if the number is positive or negative\n",
    "# And displays an appropriate message\n",
    "\n",
    "k = analyzer.polarity_scores(text)\n",
    "\n",
    "\n",
    "if k[\"compound\"] >= 0.05:\n",
    "    print(\"Positive sentiment\")\n",
    "elif k[\"compound\"] <= -0.05:\n",
    "    print(\"Negative sentiment\")\n",
    "else:\n",
    "    print(\"Neutral sentiment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing few more text sentiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"I am happy\"\n",
    "text2 = \"I think I am happy\"\n",
    "text3 = \"I doubt If I am happy\"\n",
    "text4 = \"I think I am not happy\"\n",
    "text5 = \"I am not happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.351, 'pos': 0.649, 'compound': 0.5719}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.519, 'pos': 0.481, 'compound': 0.5719}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.245, 'neu': 0.392, 'pos': 0.363, 'compound': 0.296}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.375, 'neu': 0.625, 'pos': 0.0, 'compound': -0.4585}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.5, 'neu': 0.5, 'pos': 0.0, 'compound': -0.4585}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(text5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentiment analysis with `TextBlob`\n",
    "\n",
    "https://textblob.readthedocs.io/en/dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666666666666666"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob #pip install TextBlob\n",
    "\n",
    "blob = TextBlob(test_tweet)\n",
    "blob.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with another text. News article this time. Recall this text from last lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Netanyahu's visit was cut short by reports late Sunday that a rocket was fired from Gaza into central Israel, wounding at least seven people. Following criticism from political opponents over what they consider the prime minister's unclear stance toward the militant political group, Israel responded with a series of strikes into Gaza against Hamas, which largely governs the contested strip. President Donald Trump tacitly endorsed the strike following his meetings with Netanyahu, calling the Hamas attack \\\"despicable.\\\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04285714285714285"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "blob.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2642857142857143"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few other functions available as well. Press tab to see them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseBlob.parse of TextBlob(\"Netanyahu's visit was cut short by reports late Sunday that a rocket was fired from Gaza into central Israel, wounding at least seven people. Following criticism from political opponents over what they consider the prime minister's unclear stance toward the militant political group, Israel responded with a series of strikes into Gaza against Hamas, which largely governs the contested strip. President Donald Trump tacitly endorsed the strike following his meetings with Netanyahu, calling the Hamas attack \"despicable.\"\")>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few more tests to see rule-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.8, subjectivity=0.75)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('great').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.4, subjectivity=0.75)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('not great').sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the rule above for \"not great\" is polarity of \"great\" X -0.5 = 0.8* -0.5 = -0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span class=\"mark\">TODO for fun</span>**\n",
    "\n",
    "Try with a few different variations to see whether you can observe the rules working here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Empath`\n",
    "\n",
    "https://github.com/Ejhfast/empath-client\n",
    "\n",
    "https://pypi.org/project/empath/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install empath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from empath import Empath #pip install empath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = Empath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ = lexicon.analyze(\"he hit the other person\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories for the sentence: \"he hit the other person\":\n",
      "movement\n",
      "violence\n",
      "pain\n",
      "negative_emotion\n"
     ]
    }
   ],
   "source": [
    "print('Categories for the sentence: \"he hit the other person\":')\n",
    "for key, value in categ.items():\n",
    "    if value != 0:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['help', 'office', 'dance', 'money', 'wedding', 'domestic_work', 'sleep', 'medical_emergency', 'cold', 'hate', 'cheerfulness', 'aggression', 'occupation', 'envy', 'anticipation', 'family', 'vacation', 'crime', 'attractive', 'masculine', 'prison', 'health', 'pride', 'dispute', 'nervousness', 'government', 'weakness', 'horror', 'swearing_terms', 'leisure', 'suffering', 'royalty', 'wealthy', 'tourism', 'furniture', 'school', 'magic', 'beach', 'journalism', 'morning', 'banking', 'social_media', 'exercise', 'night', 'kill', 'blue_collar_job', 'art', 'ridicule', 'play', 'computer', 'college', 'optimism', 'stealing', 'real_estate', 'home', 'divine', 'sexual', 'fear', 'irritability', 'superhero', 'business', 'driving', 'pet', 'childish', 'cooking', 'exasperation', 'religion', 'hipster', 'internet', 'surprise', 'reading', 'worship', 'leader', 'independence', 'movement', 'body', 'noise', 'eating', 'medieval', 'zest', 'confusion', 'water', 'sports', 'death', 'healing', 'legend', 'heroic', 'celebration', 'restaurant', 'violence', 'programming', 'dominant_heirarchical', 'military', 'neglect', 'swimming', 'exotic', 'love', 'hiking', 'communication', 'hearing', 'order', 'sympathy', 'hygiene', 'weather', 'anonymity', 'trust', 'ancient', 'deception', 'fabric', 'air_travel', 'fight', 'dominant_personality', 'music', 'vehicle', 'politeness', 'toy', 'farming', 'meeting', 'war', 'speaking', 'listen', 'urban', 'shopping', 'disgust', 'fire', 'tool', 'phone', 'gain', 'sound', 'injury', 'sailing', 'rage', 'science', 'work', 'appearance', 'valuable', 'warmth', 'youth', 'sadness', 'fun', 'emotional', 'joy', 'affection', 'traveling', 'fashion', 'ugliness', 'lust', 'shame', 'torment', 'economics', 'anger', 'politics', 'ship', 'clothing', 'car', 'strength', 'technology', 'breaking', 'shape_and_size', 'power', 'white_collar_job', 'animal', 'party', 'terrorism', 'smell', 'disappointment', 'poor', 'plant', 'pain', 'beauty', 'timidity', 'philosophy', 'negotiate', 'negative_emotion', 'cleaning', 'messaging', 'competing', 'law', 'friends', 'payment', 'achievement', 'alcohol', 'liquid', 'feminine', 'weapon', 'children', 'monster', 'ocean', 'giving', 'contentment', 'writing', 'rural', 'positive_emotion', 'musical'])\n"
     ]
    }
   ],
   "source": [
    "#available categories in empath\n",
    "print(categ.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how Empath works on our tweet text\n",
    "categ_tweets = lexicon.analyze(test_tweet)\n",
    "# categ_tweets ~ commented becuase gives a longer list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories for the sentence: @john lol that was #awesome :)\n"
     ]
    }
   ],
   "source": [
    "print('Categories for the sentence:', test_tweet)\n",
    "for key, value in categ_tweets.items():\n",
    "    if value != 0:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how will this work on text5\n",
    "\n",
    "categ = lexicon.analyze(text5, normalize=True)\n",
    "categ_tweets = lexicon.analyze(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories for the sentence: I am not happy\n",
      "wedding\n",
      "cheerfulness\n",
      "optimism\n",
      "childish\n",
      "celebration\n",
      "party\n",
      "positive_emotion\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Categories for the sentence:', text5)\n",
    "for key, value in categ_tweets.items():\n",
    "    if value != 0:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_text = lexicon.analyze(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories for the news sentence: I am not happy \n",
      "---------\n",
      "wedding\n",
      "cheerfulness\n",
      "optimism\n",
      "childish\n",
      "celebration\n",
      "party\n",
      "positive_emotion\n"
     ]
    }
   ],
   "source": [
    "print('Categories for the news sentence:', text5, '\\n---------')\n",
    "for key, value in categ_text.items():\n",
    "    if value != 0:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span class=\"mark\">TODO</span>**: \n",
    "\n",
    "1. From the project pitches that you all submitted, you had some idea of what data to collect. Get one data point for your problem (this could be one reddit post from a community, one tweet, etc.)\n",
    "2. Now check to see which categories of Empath are present\n",
    "3. Now loop through your entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the key file and load keys in a dictionary\n",
    "def loadKeys(key_file):\n",
    "    with open(key_file) as f:\n",
    "        key_dict = json.load(f)\n",
    "    return key_dict['api_key'], key_dict['api_secret'], key_dict['token'], key_dict['token_secret']\n",
    "\n",
    "KEY_FILE = 'keys.json'\n",
    "api_key, api_secret, token, token_secret = loadKeys(KEY_FILE)\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(token, token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mtweet :\u001b[0m When the federal government’s #COVID19 Testing and Screening Expert Advisory Panel released its first report last m… https://t.co/K5X7OxMudg\n",
      "crime\n",
      "government\n",
      "journalism\n",
      "communication\n",
      "meeting\n",
      "work\n",
      "law\n",
      "\u001b[1mtweet :\u001b[0m Hospital pastor heading into ICU to pray with #COVID19 patients &amp; administer last rites, but lets bring the governm… https://t.co/u919if9b9U\n",
      "divine\n",
      "religion\n",
      "worship\n",
      "death\n",
      "traveling\n",
      "giving\n",
      "\u001b[1mtweet :\u001b[0m Number of UK 🇬🇧 intensive care beds increased 158% in &lt;12 months due to #COVID19. Now provide 1 bed per 11,085 popu… https://t.co/AlKQSUmr3T\n",
      "help\n",
      "sleep\n",
      "medical_emergency\n",
      "furniture\n",
      "healing\n",
      "trust\n",
      "negative_emotion\n",
      "children\n",
      "giving\n",
      "positive_emotion\n",
      "\u001b[1mtweet :\u001b[0m Looking for datasets for my research project regarding Covid19's impact on labour market. https://t.co/A51KFqxeo9 #bigdata\n",
      "school\n",
      "journalism\n",
      "business\n",
      "internet\n",
      "reading\n",
      "violence\n",
      "meeting\n",
      "injury\n",
      "science\n",
      "work\n",
      "technology\n",
      "\u001b[1mtweet :\u001b[0m #Moderna CEO says the world will have to live with Covid 'forever'. (CNBC) #CoronaVirus #COVIDー19 #COVID19… https://t.co/UYhQMvzCwL\n",
      "home\n",
      "rural\n",
      "\u001b[1mtweet :\u001b[0m #COVID19 exacerbated #farmworkers' job hazards and vulnerability in a system that insufficiently protects their hea… https://t.co/hTlRpNm86N\n",
      "domestic_work\n",
      "occupation\n",
      "nervousness\n",
      "weakness\n",
      "suffering\n",
      "blue_collar_job\n",
      "computer\n",
      "fear\n",
      "programming\n",
      "neglect\n",
      "work\n",
      "sadness\n",
      "economics\n",
      "technology\n",
      "white_collar_job\n",
      "poor\n",
      "giving\n",
      "\u001b[1mtweet :\u001b[0m #RTEInvestigates very moving especially watching those who suffer from asthma. As an asthmatic, I can only imagine… https://t.co/4niO3V9cso\n",
      "health\n",
      "suffering\n",
      "neglect\n",
      "injury\n",
      "sadness\n",
      "shame\n",
      "torment\n",
      "poor\n",
      "pain\n",
      "\u001b[1mtweet :\u001b[0m @Independent_ie This sort of fear-mongering is unhelpful and irresponsible.\n",
      "And it is utterly pointless to boot.\n",
      "#COVID19\n",
      "irritability\n",
      "\u001b[1mtweet :\u001b[0m Not leaked, but purposely released. #COVID19 🇨🇳 https://t.co/fDLVsgtYNW\n",
      "\u001b[1mtweet :\u001b[0m WATCH LIVE:TRAFFIC &amp; WEATHER TOGETHER ATLANTA: #maga #trump #usa #america #republican #democrat #left #right… https://t.co/wfStc7e3vM\n",
      "\u001b[1mtweet :\u001b[0m Nursing homes are gaining ground in the fight against #COVID19. @Jay_Reeves talked to one of our members in this na… https://t.co/bKgiNF85Uc\n",
      "aggression\n",
      "dispute\n",
      "kill\n",
      "violence\n",
      "fight\n",
      "war\n",
      "breaking\n",
      "power\n",
      "negative_emotion\n",
      "competing\n",
      "\u001b[1mtweet :\u001b[0m #Seattle seeks #Cuban assistance combatting #Covid19\n",
      "\n",
      "https://t.co/LBX768xBqG\n",
      "help\n",
      "giving\n",
      "\u001b[1mtweet :\u001b[0m During our NYSC days we made face mask because of the ravaging covid 19 pandemic, them no rate us😂😂😂😂\n",
      "\n",
      "Everything s… https://t.co/lNHq6nXjto\n",
      "fear\n",
      "body\n",
      "\u001b[1mtweet :\u001b[0m For my friend - her parents have COVID &amp; she needs time to be their caretaker 💚 https://t.co/LEtfpGXacO\n",
      "help\n",
      "family\n",
      "party\n",
      "friends\n",
      "positive_emotion\n",
      "\u001b[1mtweet :\u001b[0m Look at this @BorisJohnson you sickening incompetent not my PM #COVID19 #nhscomms All you had to do was act and clo… https://t.co/6pb2oUQLHe\n",
      "speaking\n"
     ]
    }
   ],
   "source": [
    "search_term = \"COVID19\"\n",
    "new_search = search_term + \" -filter:retweets\"\n",
    "no_of_pages = 1\n",
    "\n",
    "for page in tweepy.Cursor(api.search, q = new_search, lang=\"en\",).pages(no_of_pages):\n",
    "    for status in page:\n",
    "        print(\"\\033[1mtweet :\\033[0m \" + status.text)\n",
    "        categ_text = lexicon.analyze(status.text)\n",
    "        for key, value in categ_text.items():\n",
    "            if value != 0:\n",
    "                print(key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
